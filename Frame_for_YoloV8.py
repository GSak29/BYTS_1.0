# -*- coding: utf-8 -*-
"""Hand_Sign_Reference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AGM4r36gPJtCVQkPP1CjcHXQJvENY2FP

# ***Dataset Arrangement***
"""

!pip install ultralytics #calling library in which  model is present

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# Define the path to the zip file and the extraction directory
zip_file_path = '/content/drive/MyDrive/dataset/Hospital.zip'  # Adjust this path
extraction_path = '/content/dataset'  # Destination folder

# Create the extraction directory if it doesn't exist
os.makedirs(extraction_path, exist_ok=True)

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extraction_path)

print("Unzipping completed!")

"""# ***Dataset Training***"""

import random
from ultralytics import YOLO
from PIL import Image
import matplotlib.pyplot as plt


model = YOLO("yolov8s.pt") #yolo model version8 n

# Train the model using the dataset.yaml file
results = model.train(
    data='/content/dataset/dataset/data.yaml',  # Path to your dataset.yaml file
    imgsz=640,            # Image size
    epochs=30,             # Number of epochs
    batch=16              # Batch size
)

print("Training completed!")

import os
for root, dirs, files in os.walk("/content"):
    for file in files:
        if file.endswith(".pt"):
            print(os.path.join(root, file))

"""# ***Weights Saver***"""

from google.colab import files
import shutil

# Compress the 'runs' folder
shutil.make_archive("runs", 'zip', "runs")

# Download the compressed folder
files.download("runs.zip")

"""# ***Check***"""

import cv2
from google.colab.patches import cv2_imshow
from google.colab import files
from ultralytics import YOLO  # Ensure YOLOv8 is installed

# âœ… Directly define the class names (Aâ€“Z + 1â€“9)
class_names =['Bad', 'Brother', 'Father', 'Food', 'Friend', 'Good', 'Hello', 'Help', 'House', 'I', 'Indian', 'Loud', 'Mummy', 'Namaste', 'Name', 'No', 'Place', 'Please', 'Quiet', 'Sleeping', 'Sorry', 'Strong', 'Thank-you', 'Time', 'Today', 'Water', 'What', 'Yes', 'Your', 'language', 'sign', 'you']


print(f"âœ… Loaded {len(class_names)} gesture class names:")
print(class_names)

# âœ… Load your trained YOLOv8 model
model_path = "/content/runs/detect/train/weights/best.pt"  # Update if needed
try:
    model = YOLO(model_path)
    print("âœ… Model loaded successfully!")
except Exception as e:
    print(f"âŒ Error loading YOLO model: {e}")
    raise

# ğŸ“¤ Upload ISL gesture images
print("ğŸ“¤ Upload ISL gesture images...")
uploaded = files.upload()

# ğŸ” Process each uploaded image
for file_name in uploaded.keys():
    print(f"\nğŸ” Processing: {file_name}")
    img = cv2.imread(file_name)

    if img is None:
        print(f"âŒ Error loading image: {file_name}")
        continue

    try:
        results = model.predict(img, conf=0.5)
    except Exception as e:
        print(f"âŒ Detection error: {e}")
        continue

    detected_gestures = []

    for result in results:
        if not result.boxes:
            print("âš ï¸ No detections found.")
            continue

        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])
            cls_id = int(box.cls[0])

            if cls_id >= len(class_names):
                print(f"âš ï¸ Invalid class ID: {cls_id}")
                continue

            class_name = class_names[cls_id]
            detected_gestures.append((class_name, conf, (x1, y1, x2, y2)))

    if detected_gestures:
        # Show highest confidence detection
        class_name, conf, (x1, y1, x2, y2) = max(detected_gestures, key=lambda x: x[1])
        label = f"{class_name} ({conf:.2f})"

        # Draw box & label
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        print(f"âœ… Detected Gesture: {label}")
    else:
        print("âŒ No valid gesture detected.")

    # ğŸ“¸ Show the result
    cv2_imshow(img)

print("\nğŸ‰ All detections complete!")

"""# ***Test and Valid***"""

from ultralytics import YOLO

# Load the trained YOLO model (use best model after training)
model = YOLO("/content/runs/detect/train/weights/best.pt")  # Adjust path if needed

# Run validation using the 'valid' folder
results = model.val(data="/content/dataset/data.yaml")

# Print summary of validation results
print(results)

results = model.predict(source="/content/dataset/test/images", save=True)